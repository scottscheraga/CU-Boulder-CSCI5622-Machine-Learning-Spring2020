{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Kaggle Competition\n",
    "## CSCI 5622 - Spring 2019\n",
    "#Scott Scheraga\n",
    "***\n",
    "train-features.csv contains the features of the examples / cases, separated by commas, that you will use to train your classifiers. You must associate the features found in each row / line with the output found in the corresponding row / line in train-output.csv to create a full case.\n",
    "\n",
    "test-features.csv contains the features of the examples / cases that you will need to predict using your trained model.\n",
    "\n",
    "See train.names for header descriptions of the train and test features. This will be helpful in understanding how you may need to normalize, bin, or otherwise update your data to better suit your classifiers.\n",
    "\n",
    "You can use test-submission.demo to see what an example submission file should look like. This file is a baseline case - you can even upload it to make sure your Kaggle account is working correctly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching notes:\n",
    "Intial analysis of the training set showed the following information:\n",
    "from print(traincombined['output'].value_counts())\n",
    "        print(traincombined.groupby('output').mean())\n",
    "24720 people below threshold, 7841 above.\n",
    "\n",
    "\n",
    "As marital status averages were the following, I binned by married vs unmarried due to notably different outputs. \n",
    "\n",
    "--marital-status        |||         output                   \n",
    " Divorced                    0.104209  \n",
    " Married-AF-spouse           0.434783  \n",
    " Married-civ-spouse          0.446848  \n",
    " Married-spouse-absent       0.081340  \n",
    " Never-married               0.045961  \n",
    " Separated                   0.064390  \n",
    " Widowed                     0.085599  \n",
    " \n",
    "Similarly, for relationship, I binned by Spouse vs not spouse for the same reason as above, and then decided that the relationship column was redunant to marital status, and then deleted it. \n",
    "\n",
    "--Relationship      |||  output                    \n",
    " Husband              0.448571  \n",
    " Not-in-family        0.103070  \n",
    " Other-relative       0.037717  \n",
    " Own-child            0.013220  \n",
    " Unmarried            0.063262  \n",
    " Wife                 0.475128 \n",
    " \n",
    "There is a very notable increase in capital gain and loss for people above the income threshold. I decided on a 4 bins for capital gain and capital loss. \n",
    "\n",
    "--Averages for 0--\n",
    " age 36.783738 \n",
    " education-num 9.595065 \n",
    " capital-gain 148.752468\n",
    " capital-loss 53.142921 \n",
    " hours-per-week 38.840210  \n",
    "\n",
    "--Averages for 1--\n",
    " age 44.249841\n",
    " education-num 11.611657  \n",
    " capital-gain 4006.142456  \n",
    " capital-loss 195.001530 \n",
    " hours-per-week 45.473026 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self,features):\n",
    "        self.features=features\n",
    "        \n",
    "    def preprocess(self):    \n",
    "        \n",
    "        #self.features= pd.read_csv(\"traincombined.csv\")\n",
    "        #self.features =self.features.dropna()\n",
    "        #https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "        self.features=self.features.drop(columns =\n",
    "                 [\"fnlwgt\",\"race\", \"sex\",\"native-country\",\n",
    "                  \"hours-per-week\",\"workclass\", \"education-num\",\"occupation\",\"relationship\"])\n",
    "        \n",
    "        #self.features=self.features.drop(columns = \n",
    "          #  [\"workclass\", \"educatio'DataFrame' object has no attribute 'ravel'n\",\"marital-status\",\"occupation\",\n",
    "         #    \"relationship\",\"race\",\"sex\",\"native-country\"])\n",
    "\n",
    "        \n",
    "        #print(self.features['education'].value_counts())\n",
    "        self.features['education']=np.where(self.features['education'] ==' Preschool',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 1st-4th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 5th-6th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 7th-8th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 9th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 10th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 11th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 12th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Assoc-voc',\n",
    "                                                ' Assoc-professional', self.features['education'])    \n",
    "        self.features['education']=np.where(self.features['education'] ==' Prof-school',\n",
    "                                                ' Assoc-professional', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Assoc-acdm',\n",
    "                                                ' Assoc-professional', self.features['education'])        \n",
    "        self.features['education']=np.where(self.features['education'] ==' Some-college',\n",
    "                                                ' HS-grad or Some-college', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' HS-grad',\n",
    "                                                ' HS-grad or Some-college', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Masters',\n",
    "                                                ' Graduate-degree', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Doctorate',\n",
    "                                                ' Graduate-degree', self.features['education'])\n",
    "        \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Divorced',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Never-married',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Separated',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Widowed',\n",
    "                                                ' Not Married', self.features['marital-status'])  \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-spouse-absent',\n",
    "                                                ' Not Married', self.features['marital-status'])        \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-civ-spouse',\n",
    "                                                ' Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-AF-spouse',\n",
    "                                                ' Married', self.features['marital-status'])  \n",
    "        \n",
    "        #https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "        #Normalization of continuous data\n",
    "        self.features['age'] = preprocessing.scale(self.features['age'])\n",
    "        self.features['capital-gain'] = preprocessing.scale(self.features['capital-gain'])\n",
    "        self.features['capital-loss'] = preprocessing.scale(self.features['capital-loss'])\n",
    "        #print(data_final)\n",
    "        \n",
    "        #print(self.features)\n",
    "        \n",
    "        #Need to get capital gain and loss working! Make a new collumn?\n",
    "        \n",
    "        #self.features['capital-gain']=self.features['capital-gain'].astype(float)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(self.features['capital-gain'].value_counts())\n",
    "        \n",
    "        #self.features['capital-gain']=np.where(self.features['capital-gain'].astype(float) < 149,\n",
    "          #                                      ' Low', self.features['capital-gain'])\n",
    "        \n",
    "        #self.features['capital-gain']=np.where((self.features['capital-gain'].astype(float) > 149) &\n",
    "        #         (self.features['capital-gain'].astype(float) <2077),' Mid-Low', self.features['capital-gain'])        \n",
    "        #self.features['capital-gain']=np.where((self.features['capital-gain'] > 2077) &\n",
    "           #      (self.features['capital-gain'] <4006),' Mid-High', self.features['capital-gain']) \n",
    "       \n",
    "        #self.features['capital-gain']=np.where(int(self.features['capital-gain']) > 4006,\n",
    "        #                                        ' High', self.features['capital-gain'])        \n",
    "\n",
    "        \"\"\"\n",
    "        capital losses: 0, 53.142921, 124.0722255, 195.001530, and up\n",
    "        \n",
    "        %matplotlib inline\n",
    "        pd.crosstab(self.features['age'],self.features['output']).plot(kind='bar')\n",
    "        plt.title('Purchase Frequency for Job Title')\n",
    "        plt.xlabel('Job')\n",
    "        plt.ylabel('Frequency of Purchase')\n",
    "        plt.savefig('purchase_fre_job')\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(self.features['relationship'].unique())        \n",
    "        #print(self.features['education'].value_counts())\n",
    "        #print(self.features['capital-gain'].value_counts())\n",
    "        #print(traincombined['output'].value_counts())\n",
    "        #print(self.features.groupby('marital-status').mean())\n",
    "        #print(self.features.groupby('age').mean())\n",
    "        \n",
    "\n",
    "\n",
    "        #Reference: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "        #print(self.features['education'].unique()) \n",
    "        #print(self.features['marital-status'].unique()) \n",
    "        \n",
    "        \n",
    "        category_variables=['education','marital-status']\n",
    "        for var in category_variables:\n",
    "            cat_list='var'+'_'+var\n",
    "            cat_list = pd.get_dummies(self.features[var], prefix=var)\n",
    "            data1=self.features.join(cat_list)\n",
    "            self.features=data1\n",
    "            \n",
    "        category_variables=['education','marital-status']\n",
    "        self.features_vars=self.features.columns.values.tolist()\n",
    "        to_keep=[i for i in self.features_vars if i not in category_variables]\n",
    "            \n",
    "        data_final=self.features[to_keep]\n",
    "        data_final.columns.values\n",
    "        #print(data_final.columns.values)\n",
    "        #print(data_final)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return data_final\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ' United-States'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-a8d09ff48d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m              data_train, trainoutputArray.ravel(), test_size=0.25, random_state=5)\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch #:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" Score: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ' United-States'"
     ]
    }
   ],
   "source": [
    "traindatafeatures= pd.read_csv(\"train-features_scottannotated.csv\")\n",
    "trainoutput= pd.read_csv(\"train-output_scottannotated.csv\")\n",
    "testdatafeatures= pd.read_csv(\"test-features_scottannotated.csv\")  \n",
    "\n",
    "data_train = Data(traindatafeatures).preprocess()\n",
    "data_test= Data(testdatafeatures).preprocess()\n",
    "\n",
    "\n",
    "#print(trainoutput)\n",
    "trainoutputArray=np.asarray(trainoutput)\n",
    "np.transpose(trainoutputArray)\n",
    "\n",
    "\n",
    "\n",
    "#data_test.preprocess()\n",
    "#print(data_train)\n",
    "#print(trainoutputArray.ravel())\n",
    "\n",
    "#data_final_vars=data_train.columns.values.tolist()\n",
    "\n",
    "\n",
    "        #y=['y']\n",
    "#X=[i for i in data_final_vars if i not in y]\n",
    "  \n",
    "logreg = LogisticRegression()\n",
    "\"\"\"        \n",
    "rfe = RFE(logreg, 5)\n",
    "rfe = rfe.fit(data_train, trainoutputArray.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "          \n",
    "  \n",
    "        Output for 'age' 'capital-gain' 'capital-loss' 'education_ Assoc-professional'\n",
    "        'education_ Bachelors' 'education_ Graduate-degree'\n",
    "        'education_ HS-grad or Some-college' 'education_ Some-school'\n",
    "        'marital-status_ Married' 'marital-status_ Not Married']\n",
    "        [False  True False False False False  True  True  True  True]\n",
    "        [5 1 6 4 3 2 1 1 1 1]\n",
    "\n",
    "        \n",
    "        data_final=data_final.drop(columns =\n",
    "                 [\"age\",'capital-loss', 'education_ Assoc-professional'\n",
    "        ,'education_ Bachelors', 'education_ Graduate-degree'])\n",
    "\"\"\"                                               \n",
    "for epoch in range (3):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(\n",
    "             data_train, trainoutputArray.ravel(), test_size=0.25, random_state=5)\n",
    "        \n",
    "        logreg.fit(x_train, y_train)\n",
    "        score = logreg.score(x_test, y_test)\n",
    "        print(\"Epoch #:\", epoch, \" Score: \",score) \n",
    "\"\"\" \n",
    "#To output to a file\n",
    "predictions= logreg.predict(data_test)\n",
    "rg=range(16281)\n",
    "print(predictions)\n",
    "   \n",
    "        # dictionary of lists  \n",
    "dict = {'Category': predictions }  \n",
    "     \n",
    "df = pd.DataFrame(dict) \n",
    "  \n",
    "        # saving the dataframe \n",
    "df.to_csv('ScottSubmission.csv') \n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        #train_x,test_x,train_y,test_y= train_test_split(\n",
    "         #      X,y, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
