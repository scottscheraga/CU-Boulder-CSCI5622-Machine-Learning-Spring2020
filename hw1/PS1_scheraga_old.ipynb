{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 - KNN\n",
    "## CSCI 5622 - Spring 2020\n",
    "\n",
    "For today's assignment, we will be implementing our own K-Nearest Neighbors (KNN) algorithm.\n",
    "\n",
    "*But Professor Quigley, hasn't someone else already written KNN before?*\n",
    "\n",
    "Yes, you are not the first to implement KNN, or basically any algorithm we'll work with in this class. But 1) I'll know that you know what's really going on, and 2) you'll know you can do it, because 2a) someday you might have to implement some machine learning algorithm from scratch - maybe for a new platform (do you need to run python on your SmartToaster just to get it to learn how users like their toast?), maybe because you want to tweak the algorithm (there's always a better approach...), or maybe because you're working on something important and you need to control exactly what's on there (should you really be running anaconda on your secret spy plane?).\n",
    "\n",
    "That said - we're not going to implement *everything*. We'll start by importing a few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wait a minute - didn't we just import Scikit-learn (sklearn)? The package with baked-in machine learning tools?*\n",
    "\n",
    "Yes - but it also has a ton of helper functions, including a dataset we'll be using later. But, for now, let's set up a KNNClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "\n",
    "class KNNClassifier:\n",
    "    \n",
    "    def __init__(self, X, y, k = 5):\n",
    "        \"\"\"\n",
    "        Initialize our custom KNN classifier\n",
    "        PARAMETERS\n",
    "        X - our training data features\n",
    "        y - our training data answers\n",
    "        k - the number of nearest neighbors to consider for classification\n",
    "        \"\"\"\n",
    "        self._model = sklearn.neighbors.BallTree(X)\n",
    "        self._y = y\n",
    "        self._k = k\n",
    "        self._counts = self.getCounts()\n",
    "        \n",
    "    def getCounts(self):\n",
    "        \"\"\"\n",
    "        Creates a dictionary storing the counts of each answer class found in y\n",
    "        RETURNS\n",
    "        counts - a dictionary of counts of answer classes\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 1.1\n",
    "        #TODO: Modify and/or add to counts so that it returns a count of each answer class found in y\n",
    "        #END Workspace 1.1\n",
    "        \n",
    "        counts = dict({})\n",
    "        for a in range(self._y.size):\n",
    "            if self._y[0,a] in counts:\n",
    "                    counts[self._y[0,a]]= counts[self._y[0,a]]+1\n",
    "            else: counts[self._y[0,a]] = 1\n",
    "                \n",
    "        #print(counts)    \n",
    "        return(counts)\n",
    "    \n",
    "    def majority(self, indices):\n",
    "        \"\"\"\n",
    "        Given indices, report the majority label of those points.\n",
    "        For a tie, report the most common label in the data set.\n",
    "        PARAMETERS\n",
    "        indices - an np.array, where each element is an index of a neighbor\n",
    "        RETURNS\n",
    "        label - the majority label of our neighbors\n",
    "        \"\"\"\n",
    "        label = 0\n",
    "        countsmaj = dict({})\n",
    "        #print(\"indices\")\n",
    "        #print(indices)\n",
    "        for i in indices: \n",
    "            #print(self._y[0,i])\n",
    "            if self._y[0,i] in countsmaj:\n",
    "                countsmaj[self._y[0,i]]= countsmaj[self._y[0,i]]+1\n",
    "            else: countsmaj[self._y[0,i]] = 1\n",
    "        #print(\"k closest neighbor values= \",countsmaj)      \n",
    "        \n",
    "        #dict is made up  of {keys:values}\n",
    "        # Reference: https://stackoverflow.com/questions/42044090/return-the-maximum-value-from-a-dictionary/42044202\n",
    "        max_value = max(countsmaj.values())  # get majority quantity\n",
    "        max_keys = [u for u, v in countsmaj.items() if v == max_value] # getting all keys containing the `maximum`\n",
    "\n",
    "        #len(max_keys)\n",
    "        #print(max_value, max_keys)\n",
    "        #print(\"max values\")\n",
    "        #print (max_value)\n",
    "        #print(\"max keys\")\n",
    "        #print (max_keys)\n",
    "        if len(max_keys)==1: #No tie\n",
    "            #print(max_value)\n",
    "            label = max_keys\n",
    "        else: #run getCounts()\n",
    "        #create list of quantities (listmax) of the keys of the full set of points,\n",
    "        #that tied from only looking at the keys at the indicies\n",
    "            listmax=[] \n",
    "            for j in max_keys:\n",
    "                listmax.append(self._counts[j])\n",
    "            print(\"quantities of each of the max keys in the entire array\")\n",
    "            print (listmax)\n",
    "    #find index of largest quantity, and then use that index  in max_keys. That breaks the tie. \n",
    "            print (max_keys[listmax.index(max(listmax))])\n",
    "            label = max_keys[listmax.index(max(listmax))]\n",
    "            label=label[0]\n",
    "        return(label)\n",
    "    \n",
    "    def classify(self, point):\n",
    "        \"\"\"\n",
    "        Given a new data point, classify it according to the training data X \n",
    "        and our number of neighbors k into the appropriate class in our \n",
    "        training answers y\n",
    "        PARAMETERS\n",
    "        point - a feature vector of our test point\n",
    "        RETURNS\n",
    "        ans - our predicted classification\n",
    "        \"\"\"\n",
    "        ans = 0\n",
    "        #BEGIN Workspace 1.3\n",
    "        #TODO: perform classification of point here\n",
    "        #HINT: use the majority function created above\n",
    "        #HINT: use the euclidian distance discussed in lecture to find nearest neighbors\n",
    "        #END Workspace 1.3\n",
    "                    \n",
    "        #print(\"k =\",self._k)\n",
    "        \n",
    "        dist, ind = self._model.query(point,self._k )  \n",
    "        #print(\"ind= \",ind) # indices of k closest neighbors \n",
    "        #print(\"distances= \", dist) # distances to k closest neighbors\n",
    "        \n",
    "        ans= self.majority(ind[0])\n",
    "        #print(\"majority= \", ans)\n",
    "        \n",
    "        return(ans)\n",
    "    \n",
    "    def confusionMatrix(self, testX, testY):\n",
    "        \"\"\"\n",
    "        Generate a confusion matrix for the given test set\n",
    "        PARAMETERS\n",
    "        testX - an np.array of feature vectors of test points\n",
    "        testY - the corresponding correct classifications of our test set\n",
    "        RETURN\n",
    "        C - an N*N np.array of counts, where N is the number of classes \n",
    "        in our classifier\n",
    "        \"\"\"\n",
    "        #print(\"test x=\", testX)\n",
    "        #print(\"test y= \",testY)\n",
    "        \n",
    "        \n",
    "        #create an array of each point's actual value (column 0)\n",
    "        #and values guessed for each test point (column 1)\n",
    "        comptable= np.zeros((testX.shape[0],2))\n",
    "\n",
    "        for b in range(testX.shape[0]):\n",
    "                #print(\"---------------\")\n",
    "                #print(\"point to test= \",testX[b:(b+1)])\n",
    "                comptable[b,0]= testY[0,b]\n",
    "                comptable[b,1]= self.classify(testX[b:(b+1)])\n",
    "        #print(\"---------------\")\n",
    "        #print(\"actual vs guess= \")\n",
    "        #print(comptable)\n",
    "        \n",
    "        #create lookup dictionary of index and answers\n",
    "        #values are indicies,keys are answers\n",
    "        countsmain= self.getCounts()\n",
    "        #print(\"getCounts= \", countsmain)\n",
    "        lookupdict = {}\n",
    "        increm=0\n",
    "        for r in countsmain:\n",
    "            lookupdict[r]=increm\n",
    "            increm+=1    \n",
    "            \n",
    "        #print(\"lookup dictionary= \")\n",
    "        #print(lookupdict)\n",
    "        \n",
    "        #create an N*N array with N= number of classes\n",
    "        confmatrix= np.zeros((len(countsmain),len(countsmain)))\n",
    "        #in confmatrix, the rows are the actual values,\n",
    "        #and the columns are the guesses\n",
    "        for row in range(len(lookupdict)):\n",
    "                for col in range(len(lookupdict)):\n",
    "                    for k in range(testX.shape[0]):\n",
    "                        if lookupdict[comptable[k,0]]==row and lookupdict[comptable[k,1]]==col:\n",
    "                            confmatrix[row,col]+=1\n",
    "                            #print(\"MATCH!\")\n",
    "                            #print(\"row= \",row)\n",
    "                            #print(\"col= \",col)\n",
    "                        #else:\n",
    "                            #print(\"no match\")\n",
    "                            #print(\"row= \",row)\n",
    "                            #print(\"col= \",col)\n",
    "        print(\"confusion matrix= \")    \n",
    "        print(confmatrix)    \n",
    "            \n",
    "        \n",
    "\n",
    "        #C = np.array()\n",
    "        #BEGIN Workspace 1.4\n",
    "        #TODO: Run classification for the test set, compare to test answers,\n",
    "        #and add counts to matrix\n",
    "        #END Workspace 1.4\n",
    "        C = confmatrix\n",
    "        return(C)\n",
    "    \n",
    "    def accuracy(self, C):\n",
    "        \"\"\"\n",
    "        Generate an accuracy score for the classifier based on the confusion matrix\n",
    "        PARAMETERS\n",
    "        C - an np.array of counts\n",
    "        RETURN\n",
    "        score - an accuracy score\n",
    "        \"\"\"\n",
    "        score = np.sum(C.diagonal()) / C.sum()\n",
    "        print(\"score= \", score)\n",
    "        return(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But professor, this code isn't complete!*\n",
    "\n",
    "### Problem 1: Complete our KNN Classifier - 40 Points (10 each)\n",
    "\n",
    "1.1 - Complete the getCounts function to return the count of each class found in the training set\n",
    "\n",
    "1.2 - Complete the majority function to determine the majority class of a series of neighbors\n",
    "\n",
    "1.3 - Complete the classify function to capture the predicted class of a new datapoint\n",
    "\n",
    " - HINT: Use the BallTree documentation to determine how to retrieve neighbors from the model (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree)\n",
    "\n",
    "1.4 - Complete the confusionMatrix function to reveal the results of classification\n",
    "\n",
    "You can take a look at the unit tests below to see how we create data to input into our classifier, what kinds of things we expect as output, etc. You should also consider expanding the test cases to make sure your classifier is working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".E\n",
      "======================================================================\n",
      "ERROR: testKNNOne (__main__.KNNTester)\n",
      "----------------------------------------------------------------------\n",
      "TypeError: float() argument must be a string or a number, not 'list'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-13-e403f2b495b7>\", line 32, in testKNNOne\n",
      "    CC= self.knnconfusion.confusionMatrix(self.x[5:7], self.y[:1,5:7])\n",
      "  File \"<ipython-input-12-ae449be01df9>\", line 135, in confusionMatrix\n",
      "    comptable[b,1]= self.classify(testX[b:(b+1)])\n",
      "ValueError: setting an array element with a sequence.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.005s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=1 failures=0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class KNNTester(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.x = np.array([[3,1],[2,8], [2,7], [5,2],[3,2],[8,2],[2,4]])\n",
    "        self.y = np.array([[1, -1, -1, 1, -1, 1, -1]])\n",
    "        self.knnfive = KNNClassifier(self.x, self.y)\n",
    "        self.knnthree = KNNClassifier(self.x, self.y, 3)\n",
    "        self.knnone = KNNClassifier(self.x, self.y, 1)\n",
    "        \n",
    "        #test case that uses last two items of each array as the test case\n",
    "        self.knnconfusion = KNNClassifier(self.x[0:4], self.y[:1,0:4], 3)\n",
    "        \n",
    "        self.testPoints = np.array([[2,1], [2,6], [4, 4]])\n",
    "        \n",
    "    def testCounter(self):\n",
    "        \"\"\"\n",
    "        Test getCounts function from knnclassifier\n",
    "        \"\"\"\n",
    "        #self.assertEqual(self.knnfive._counts[1], 3)\n",
    "        #self.assertEqual(self.knnfive._counts[-1], 4)\n",
    "  \n",
    "    def testKNNOne(self):\n",
    "        \n",
    "        #Test if the classifier returns \"correct\" (expected) classifications for k = 1\n",
    "        #self.assertEqual(self.knnone.classify(self.testPoints[0]), 1)\n",
    "       \n",
    "        \n",
    "        #self.assertEqual(self.knnthree.classify(self.testPoints[:1]), -1)\n",
    "        \n",
    "    \n",
    "        CC= self.knnconfusion.confusionMatrix(self.x[5:7], self.y[:1,5:7])\n",
    "        self.knnconfusion.accuracy(CC)\n",
    "        \n",
    "        #BEGIN Workspace\n",
    "        #Add more tests as desired\n",
    "        #END Workspace\n",
    "    \n",
    "    #BEGIN Workspace\n",
    "    #Add more test functions as desired\n",
    "    #HINT - You'll want to make sure each of your functions from the\n",
    "    #KNNClassifier class you created work correctly...\n",
    "    #END Workspace\n",
    "    \n",
    "tests = KNNTester()\n",
    "myTests = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(myTests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - now we've demonstrated that our KNN classifier works, let's think about our problem space! \n",
    "\n",
    "## Our Dataset - Identifying Digits from Images\n",
    "\n",
    "It's a pretty common problem - just imagine working at the post office, or at a bank, and you're handed a hand-written envelope, or check, or other piece of information and you have to identify exactly what it says. Did they pay 500 or 600 dollars? Is the letter going to 80309 (campus) or 30309 (Atlanta)?\n",
    "\n",
    "Let's be a little smart about this - let's up some classes and helper functions to help us out.\n",
    "\n",
    "### Problem 2: Implement KNN on Digits dataset - 30 Points\n",
    "\n",
    "2.1 Randomly divide our Digits dataset into training and testing sets (15 Points)\n",
    "\n",
    "2.2 Report the number of examples in training and testing, as well as measuring then number of pixels in each image (5 points)\n",
    "\n",
    "2.3 Create a confusion matrix of our classifier for K = 5 (10 points) *HINT: Doing this may cause you to catch mistakes in your classifier. Go fix those!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape=  (1797, 64)\n",
      "train_x shape=  (1437, 64)\n",
      "train_y shape=  (1437,)\n",
      "test_x shape=  (360, 64)\n",
      "test_y shape=  (360,)\n",
      "Image size = (8, 8)\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth=  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1389ab5e9757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ground truth= \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mtests2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNumbers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#myTests = unittest.TestLoader().loadTestsFromModule(tests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1389ab5e9757>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewDigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m266\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m266\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#print(self.train_x[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1389ab5e9757>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mconfusion\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnconfusion2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mDC\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnconfusion2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknnconfusion2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b061244dd191>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, y, k)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetCounts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b061244dd191>\u001b[0m in \u001b[0;36mgetCounts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                     \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "\n",
    "class Numbers:\n",
    "    def __init__(self):\n",
    "        #load data from sklearn\n",
    "        digits = sklearn.datasets.load_digits()\n",
    "        from sklearn import svm, metrics\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        #BEGIN Workspace 2.1\n",
    "        #TODO: Divide our dataset into Train and Test datasets (80/20 split), replacing the variables above\n",
    "        #END Workspace 2.1\n",
    "        \n",
    "        #reference: https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html\n",
    "        # The data that we are interested in is made of 8x8 images of digits, let's\n",
    "        # have a look at the first 4 images, stored in the `images` attribute of the\n",
    "        # dataset.  If we were working from image files, we could load them using\n",
    "        # matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "        # images, we know which digit they represent: it is given in the 'target' of\n",
    "        # the dataset.\n",
    "        \n",
    "            \n",
    "        # To apply a classifier on this data, we need to flatten the image, to\n",
    "        # turn the data in a (samples, feature) matrix:\n",
    "        n_samples = len(digits.images)\n",
    "        data = digits.images.reshape((n_samples, -1))\n",
    "        #reshape images into a 1x64 array\n",
    "        \n",
    "        #data64 = digits.images.reshape(64)\n",
    "        \n",
    "        \n",
    "        self.train_x,self.test_x,self.train_y,self.test_y= train_test_split(\n",
    "            data, digits.target, test_size=0.2, shuffle=True)\n",
    "        \n",
    "      \n",
    "       \n",
    "        \n",
    "        print(\"dataset shape= \",data.shape)\n",
    "        \n",
    "        self.report(digits)\n",
    "        self.viewDigit(digits.images[266],digits.target[266])\n",
    "        self.classify()\n",
    "        #print(self.train_x[0])\n",
    "        \n",
    "    def report(self,digits):\n",
    "        \"\"\"\n",
    "        Report information about the dataset using the print() function\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"train_x shape= \",self.train_x.shape)\n",
    "        print(\"train_y shape= \",self.train_y.shape)\n",
    "        print(\"test_x shape= \",self.test_x.shape)\n",
    "        print(\"test_y shape= \",self.test_y.shape)\n",
    "        \n",
    "        print(\"Image size =\",digits.images[0].shape)\n",
    "        print(digits.images[0])\n",
    "        \n",
    "        #print(\"Reshaped\")\n",
    "        #print(np.reshape(digits.images[0],(64)))\n",
    "        #print(self.train_y[0])\n",
    "        # \n",
    "        #self.train_y \n",
    "        \n",
    "        #self.test_x\n",
    "        #self.test_y\n",
    "        #BEGIN Workspace 2.2\n",
    "        #TODO: Create printouts for reporting the size of each set and the size of each datapoint\n",
    "        #END Workspace 2.2\n",
    "        \n",
    "\n",
    "    def classify(self):\n",
    "        \"\"\"\n",
    "        Create a classifier using the training data and generate a \n",
    "        confusion matrix for the test data\n",
    "        \"\"\"\n",
    "        self.knnconfusion2 = KNNClassifier(self.train_x, self.train_y, 5)\n",
    "        DC= self.knnconfusion2.confusionMatrix(self.test_x, self.test_y)\n",
    "        self.knnconfusion2.accuracy(DC)\n",
    "        \n",
    "        #BEGIN Workspace 2.3\n",
    "        #TODO: Create classifier from training data, generate confusion\n",
    "        #matrix for test data\n",
    "        #END Workspace 2.3\n",
    "        \n",
    "    def viewDigit(self, digitImage, target):\n",
    "        \"\"\"\n",
    "        Display an image of a digit\n",
    "        PARAMETERS\n",
    "        digitImage - a data object from the dataset\n",
    "        \"\"\"\n",
    "        plt.gray()\n",
    "        plt.matshow(digitImage)\n",
    "        plt.show()\n",
    "        print(\"ground truth= \",target)\n",
    "        \n",
    "tests2 = Numbers()\n",
    "\n",
    "#myTests = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "#unittest.TextTestRunner().run(myTests)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wow, I can't believe we just created a KNN Classifier - but can't we make it better?*\n",
    "\n",
    "Yes, we saw above that our classifier didn't work perfectly. Let's explore that issue a little further\n",
    "\n",
    "### Problem 3: Improving KNN on Digits - 30 Points\n",
    "\n",
    "3.1 Determine which classes are most often confused (from our confusion matrix above), inspect some examples of these digits (using the viewDigit function in our Numbers class), and write a brief (4 - 5 sentences) description of why you think these particular numbers may be misclassified.\n",
    "\n",
    "3.2 Explore the influence of the number of nearest neighbors (i.e. try changing our K). Plot the relationship between K and accuracy, and write a brief (4 - 5 sentences) description of how this factor impacts our accuracy.\n",
    "\n",
    "3.3 (Bonus) Explore the influence of the train / test split of our data (i.e. copy our Numbers class into Numbers2 below and try changing the split for our dataset). Plot the relationship between the split % and accuracy, and write a brief (4 - 5 sentences) description of its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEGIN 3.1a\n",
    "#TODO: Print out problem class images\n",
    "#END 3.1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1b\n",
    "TODO: Write description of misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numbers2:\n",
    "    def __init__(self, trainPercentage):\n",
    "        #load data from sklearn\n",
    "        digits = sklearn.datasets.load_digits()\n",
    "        \n",
    "        #BEGIN Workspace 3.3a\n",
    "        self.train_x = np.array() # A 2D np.array of training examples, REPLACE\n",
    "        self.train_y = np.array() # A 1D np.array of training answers, REPLACE\n",
    "        self.test_x = np.array() # A 2D np.array of testing examples, REPLACE\n",
    "        self.test_y = np.array() # A 1D np.array of testing answers, REPLACE\n",
    "        #TODO: Divide our dataset into Train and Test datasets (using trainPercentage), replacing the variables above\n",
    "        #HINT: You should be able to mostly copy your own work from the original Numbers class\n",
    "        #END Workspace 3.3a\n",
    "\n",
    "    def classify(self, k):\n",
    "        \"\"\"\n",
    "        Create a classifier using the training data and generate a confusion matrix for the test data\n",
    "        \"\"\"\n",
    "        #BEGIN Workspace 3.2a\n",
    "        #TODO: Create classifier from training data (using k nearest neighbors), generate confusion matrix for test data\n",
    "        #HINT: You can copy your own work from the original Numbers class\n",
    "        #END Workspace 3.2a\n",
    "        \n",
    "    def viewDigit(digitImage):\n",
    "        \"\"\"\n",
    "        Display an image of a digit\n",
    "        PARAMETERS\n",
    "        digitImage - a data object from the dataset\n",
    "        \"\"\"\n",
    "        plt.gray()\n",
    "        plt.matshow(digitImage)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2b\n",
    "TODO: Write description of influence of neighbor count\n",
    "\n",
    "#### 3.3b\n",
    "TODO: Write description of influence of training / testing split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
