{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - Kaggle Competition\n",
    "## CSCI 5622 - Spring 2019\n",
    "#Scott Scheraga\n",
    "***\n",
    "train-features.csv contains the features of the examples / cases, separated by commas, that you will use to train your classifiers. You must associate the features found in each row / line with the output found in the corresponding row / line in train-output.csv to create a full case.\n",
    "\n",
    "test-features.csv contains the features of the examples / cases that you will need to predict using your trained model.\n",
    "\n",
    "See train.names for header descriptions of the train and test features. This will be helpful in understanding how you may need to normalize, bin, or otherwise update your data to better suit your classifiers.\n",
    "\n",
    "You can use test-submission.demo to see what an example submission file should look like. This file is a baseline case - you can even upload it to make sure your Kaggle account is working correctly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching notes:\n",
    "Intial analysis of the training set showed the following information:\n",
    "from print(traincombined['output'].value_counts())\n",
    "        print(traincombined.groupby('output').mean())\n",
    "24720 people below threshold, 7841 above.\n",
    "\n",
    "\n",
    "As marital status averages were the following, I binned by married vs unmarried due to notably different outputs. \n",
    "\n",
    "--marital-status        |||         output                   \n",
    " Divorced                    0.104209  \n",
    " Married-AF-spouse           0.434783  \n",
    " Married-civ-spouse          0.446848  \n",
    " Married-spouse-absent       0.081340  \n",
    " Never-married               0.045961  \n",
    " Separated                   0.064390  \n",
    " Widowed                     0.085599  \n",
    " \n",
    "Similarly, for relationship, I binned by Spouse vs not spouse for the same reason as above, and then decided that the relationship column was redunant to marital status, and then deleted it. \n",
    "\n",
    "--Relationship      |||  output                    \n",
    " Husband              0.448571  \n",
    " Not-in-family        0.103070  \n",
    " Other-relative       0.037717  \n",
    " Own-child            0.013220  \n",
    " Unmarried            0.063262  \n",
    " Wife                 0.475128 \n",
    " \n",
    "Workclass:\n",
    "workclass      |||output                                          \n",
    " Self-emp-inc      0.557348\n",
    " Federal-gov       0.386458\n",
    " Local-gov         0.294792\n",
    " Self-emp-not-inc  0.284927\n",
    " State-gov         0.271957\n",
    " Private           0.218673\n",
    " ?                 0.104031\n",
    " Without-pay       0.000000\n",
    " Never-worked      0.000000\n",
    " \n",
    "There is a very notable increase in capital gain and loss for people above the income threshold. I decided on a 4 bins for capital gain and capital loss. \n",
    "\n",
    "--Averages for 0--\n",
    " age 36.783738 \n",
    " education-num 9.595065 \n",
    " capital-gain 148.752468\n",
    " capital-loss 53.142921 \n",
    " hours-per-week 38.840210  \n",
    "\n",
    "--Averages for 1--\n",
    " age 44.249841\n",
    " education-num 11.611657  \n",
    " capital-gain 4006.142456  \n",
    " capital-loss 195.001530 \n",
    " hours-per-week 45.473026 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self,features):\n",
    "        self.features=features\n",
    "        \n",
    "    def preprocess(self):    \n",
    "        \n",
    "        #self.features= pd.read_csv(\"traincombined.csv\")\n",
    "        #self.features =self.features.dropna()\n",
    "        #https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "        self.features=self.features.drop(columns =\n",
    "                 [\"race\",'native-country','education'])\n",
    "        \n",
    "        #self.features=self.features.drop(columns = \n",
    "          #  [\"workclass\", \"educatio'DataFrame' object has no attribute 'ravel'n\",\"marital-status\",\"occupation\",\n",
    "         #    \"relationship\",\"race\",\"relationship\",\"occupation\",\"sex\",\"fnlwgt\",\"native-country\"])\n",
    "\n",
    "        \n",
    "        #print(self.features['education'].value_counts())\n",
    "        self.features['sex']=np.where(self.features['sex'] ==' Female',\n",
    "                                                1, self.features['sex'])\n",
    "        self.features['sex']=np.where(self.features['sex'] ==' Male',\n",
    "                                                0, self.features['sex'])\n",
    "        \n",
    "        #I might be losing data heere. Try splitting!\n",
    "        \"\"\"\n",
    "        self.features['education']=np.where(self.features['education'] ==' Preschool',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 1st-4th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 5th-6th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 7th-8th',\n",
    "                                                ' Some-school', self.features['education'])  \n",
    "        \n",
    "        self.features['education']=np.where(self.features['education'] ==' 9th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 10th',\n",
    "                                                ' Some-school', self.features['education'])       \n",
    "        self.features['education']=np.where(self.features['education'] ==' 11th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' 12th',\n",
    "                                                ' Some-school', self.features['education'])\n",
    "        \n",
    "        \n",
    "        self.features['education']=np.where(self.features['education'] ==' Assoc-voc',\n",
    "                                                ' Assoc-professional', self.features['education'])    \n",
    "        self.features['education']=np.where(self.features['education'] ==' Prof-school',\n",
    "                                                ' Assoc-professional', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Assoc-acdm',\n",
    "                                                ' Assoc-professional', self.features['education'])        \n",
    "        self.features['education']=np.where(self.features['education'] ==' Some-college',\n",
    "                                                ' HS-grad or Some-college', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' HS-grad',\n",
    "                                                ' HS-grad or Some-college', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Masters',\n",
    "                                                ' Graduate-degree', self.features['education'])\n",
    "        self.features['education']=np.where(self.features['education'] ==' Doctorate',\n",
    "                                                ' Graduate-degree', self.features['education'])\n",
    "       \n",
    "       \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Divorced',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Never-married',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Separated',\n",
    "                                                ' Not Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Widowed',\n",
    "                                                ' Not Married', self.features['marital-status'])  \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-spouse-absent',\n",
    "                                                ' Not Married', self.features['marital-status'])        \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-civ-spouse',\n",
    "                                                ' Married', self.features['marital-status'])    \n",
    "        self.features['marital-status']=np.where(self.features['marital-status'] ==' Married-AF-spouse',\n",
    "                                                ' Married', self.features['marital-status'])  \n",
    "        \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Never-worked',\n",
    "                                                ' Zero', self.features['workclass']) \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Without-pay',\n",
    "                                                ' Zero', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' ?',\n",
    "                                                ' Low', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Private',\n",
    "                                                ' Low', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' State-gov',\n",
    "                                                ' Mid', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-not-inc',\n",
    "                                                ' Mid', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Local-gov',\n",
    "                                                ' Mid', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Federal-gov',\n",
    "                                                ' High', self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-inc',\n",
    "                                                ' High', self.features['workclass'])  \n",
    "        \n",
    "        #Label Encoding\n",
    "        \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Never-worked',\n",
    "                                                1, self.features['workclass']) \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Without-pay',\n",
    "                                                1, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' ?',\n",
    "                                                2, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Private',\n",
    "                                                2, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' State-gov',\n",
    "                                                3, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-not-inc',\n",
    "                                                3, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Local-gov',\n",
    "                                                3, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Federal-gov',\n",
    "                                                4, self.features['workclass'])  \n",
    "        self.features['workclass']=np.where(self.features['workclass'] ==' Self-emp-inc',\n",
    "                                                4, self.features['workclass']) \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #A lot of people dumped coutnry for good or bad...\n",
    "        #0 mean output from test set\n",
    "        country1 = [' Holand-Netherlands', ' Outlying-US(Guam-USVI-etc)']\n",
    "        #less than 0.1 mean output from test set\n",
    "        country2 = [' Dominican-Republic',' Columbia',' Guatemala',' Mexico', \n",
    "                    ' Nicaragua',' Peru',' Vietnam', ' Honduras',' Guatemala',' El-Salvador',' Haiti']\n",
    "        # 0.1 to 0.2 mean output from test set\n",
    "        country3 = [' Puerto-Rico',' Trinadad&Tobago',' Portugal',' Laos', \n",
    "                    ' Jamaica',' Ecuador',' Thailand']\n",
    "        #0.2-0.3 mean output from test set\n",
    "        country4 = [' Poland',' South',' Ireland',' Hungary',' United-States',\n",
    "                    ' Scotland',' ?',' Ecuador',' Cuba',' China',' Greece'] \n",
    "        #0.3-0.4 mean output from test set\n",
    "        country5 = [' Hong',' Philippines',' Germany',' Canada',' England',\n",
    "                    ' Italy',' Cambodia',' Yugoslavia',' Japan',' Taiwan']         \n",
    "        #greater than 0.4 mean output from test set\n",
    "        country6 = [' India',' France',' Iran']      \n",
    "        \n",
    "        \"\"\"  \n",
    "        for x in country1:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup1', self.features['native-country']) \n",
    "        for x in country2:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup2', self.features['native-country']) \n",
    "        for x in country3:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup3', self.features['native-country'])         \n",
    "        for x in country4:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup4', self.features['native-country']) \n",
    "        for x in country5:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup5', self.features['native-country'])         \n",
    "        for x in country6:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                ' countrygroup6', self.features['native-country'])          \n",
    "        \n",
    "        #Label Encoding\n",
    "        \n",
    "        for x in country1:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                1, self.features['native-country']) \n",
    "        for x in country2:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                2, self.features['native-country']) \n",
    "        for x in country3:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                3, self.features['native-country'])         \n",
    "        for x in country4:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                4, self.features['native-country']) \n",
    "        for x in country5:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                5, self.features['native-country'])         \n",
    "        for x in country6:\n",
    "            self.features['native-country']=np.where(self.features['native-country'] == x,\n",
    "                                                6, self.features['native-country'])          \n",
    "             \n",
    "        \"\"\"\n",
    "        \n",
    "        #https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9\n",
    "        #https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "        #Normalization of continuous data\n",
    "        \n",
    "        #self.features['education-num'] = preprocessing.scale(self.features['education-num'])\n",
    "        #self.features[\"fnlwgt\"] = preprocessing.scale(self.features[\"fnlwgt\"])\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        normscalefeatures=['capital-gain','capital-loss','education-num',\"hours-per-week\",\"fnlwgt\",\"age\"]\n",
    "        for n in normscalefeatures:\n",
    "           # self.features[n] = preprocessing.normalize(self.features[n])\n",
    "            self.features[n] = preprocessing.scale(self.features[n])\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        #scaler1 = MinMaxScaler(feature_range = (0,1))\n",
    "        #scaler1.fit_transform(self.features['capital-gain'].values.reshape(-1, 1))\n",
    "        #scaler2 = MinMaxScaler(feature_range = (0,1))\n",
    "        #scaler2.fit_transform(self.features['capital-loss'].values.reshape(-1, 1))\n",
    "        #scaler3 = MinMaxScaler()\n",
    "        #scaler3.fit_transform(self.features['age'].values.reshape(-1, 1))\n",
    "        #scaler4 = MinMaxScaler(feature_range = (0,1))\n",
    "        #scaler4.fit_transform(self.features['education-num'].values.reshape(-1, 1))\n",
    "        #scaler5 = MinMaxScaler()\n",
    "        #scaler5.fit_transform(self.features['fnlwgt'].values.reshape(-1, 1))\n",
    "\n",
    "        \n",
    "     \n",
    "        #self.features['capital-gain']=np.where(self.features['capital-gain'].astype(float) < 149,\n",
    "          #                                      ' Low', self.features['capital-gain'])\n",
    "        \n",
    "        #self.features['capital-gain']=np.where((self.features['capital-gain'].astype(float) > 149) &\n",
    "        #         (self.features['capital-gain'].astype(float) <2077),' Mid-Low', self.features['capital-gain'])        \n",
    "        #self.features['capital-gain']=np.where((self.features['capital-gain'] > 2077) &\n",
    "           #      (self.features['capital-gain'] <4006),' Mid-High', self.features['capital-gain']) \n",
    "       \n",
    "        #self.features['capital-gain']=np.where(int(self.features['capital-gain']) > 4006,\n",
    "        #                                        ' High', self.features['capital-gain'])        \n",
    "\n",
    "        \"\"\"\n",
    "        capital losses: 0, 53.142921, 124.0722255, 195.001530, and up\n",
    "        \"\"\"\n",
    "\n",
    "        #Reference: https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "\n",
    "        \n",
    "        category_variables=['marital-status','workclass',\"occupation\",\"relationship\"] #'education',,'workclass'\n",
    "        for var in category_variables:\n",
    "            cat_list='var'+'_'+var\n",
    "            cat_list = pd.get_dummies(self.features[var], prefix=var)\n",
    "            data1=self.features.join(cat_list)\n",
    "            self.features=data1\n",
    "            \n",
    "        category_variables=['marital-status','workclass',\"occupation\",\"relationship\"] #,'education',\"relationship\"\n",
    "        self.features_vars=self.features.columns.values.tolist()\n",
    "        to_keep=[i for i in self.features_vars if i not in category_variables]\n",
    "        \n",
    "        \n",
    "        \n",
    "        data_final=self.features[to_keep]\n",
    "        #data_final=data_final.drop(columns = [   \n",
    "         #   'education_ Graduate-degree','education_ HS-grad or Some-college',\n",
    "         #   'education_ Assoc-professional','education_ Bachelors']) \n",
    "        \n",
    "        \n",
    "        #'workclass_ Low','workclass_ Mid','education_ Bachelors'\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        data_final=data_final.drop(columns =\n",
    "                 [,'workclass_ High'])\n",
    "        \n",
    "        data_final=data_final.drop(columns =['age','education-num','capital-loss',\n",
    "         'education_ Assoc-professional','education_ Some-school',\n",
    "         'native-country_ countrygroup1','native-country_ countrygroup3',\n",
    "         'native-country_ countrygroup4','native-country_ countrygroup5'])\n",
    "        \n",
    "        \n",
    "        data_final.columns.values\n",
    "        \n",
    "        #print(data_final)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return data_final\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'fnlwgt' 'education-num' 'sex' 'capital-gain' 'capital-loss'\n",
      " 'hours-per-week' 'marital-status_ Divorced'\n",
      " 'marital-status_ Married-AF-spouse' 'marital-status_ Married-civ-spouse'\n",
      " 'marital-status_ Married-spouse-absent' 'marital-status_ Never-married'\n",
      " 'marital-status_ Separated' 'marital-status_ Widowed' 'education_ 10th'\n",
      " 'education_ 11th' 'education_ 12th' 'education_ 1st-4th'\n",
      " 'education_ 5th-6th' 'education_ 7th-8th' 'education_ 9th'\n",
      " 'education_ Assoc-acdm' 'education_ Assoc-voc' 'education_ Bachelors'\n",
      " 'education_ Doctorate' 'education_ HS-grad' 'education_ Masters'\n",
      " 'education_ Preschool' 'education_ Prof-school' 'education_ Some-college'\n",
      " 'workclass_ ?' 'workclass_ Federal-gov' 'workclass_ Local-gov'\n",
      " 'workclass_ Never-worked' 'workclass_ Private' 'workclass_ Self-emp-inc'\n",
      " 'workclass_ Self-emp-not-inc' 'workclass_ State-gov'\n",
      " 'workclass_ Without-pay' 'occupation_ ?' 'occupation_ Adm-clerical'\n",
      " 'occupation_ Armed-Forces' 'occupation_ Craft-repair'\n",
      " 'occupation_ Exec-managerial' 'occupation_ Farming-fishing'\n",
      " 'occupation_ Handlers-cleaners' 'occupation_ Machine-op-inspct'\n",
      " 'occupation_ Other-service' 'occupation_ Priv-house-serv'\n",
      " 'occupation_ Prof-specialty' 'occupation_ Protective-serv'\n",
      " 'occupation_ Sales' 'occupation_ Tech-support'\n",
      " 'occupation_ Transport-moving' 'relationship_ Husband'\n",
      " 'relationship_ Not-in-family' 'relationship_ Other-relative'\n",
      " 'relationship_ Own-child' 'relationship_ Unmarried' 'relationship_ Wife']\n",
      "Epoch #: 0  Score:  0.8483266809947805   Train Score:  0.8526902513934705\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bestscore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3efd07613052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mtrainindexcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbestscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mtempscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bestscore' is not defined"
     ]
    }
   ],
   "source": [
    "traindatafeatures= pd.read_csv(\"train-features_scottannotated.csv\")\n",
    "trainoutput= pd.read_csv(\"train-output_scottannotated.csv\")\n",
    "testdatafeatures= pd.read_csv(\"test-features_scottannotated.csv\")  \n",
    "\n",
    "data_train = Data(traindatafeatures).preprocess()\n",
    "data_test= Data(testdatafeatures).preprocess()\n",
    "#Data_train= (32561, 45)\n",
    "#Data_Test= (16281, 45)\n",
    "\n",
    "combinedData = pd.concat([data_train,data_test])\n",
    "\n",
    "normscalefeatures=['capital-gain','capital-loss','education-num',\"hours-per-week\",\"fnlwgt\",\"age\"]\n",
    "for n in normscalefeatures:\n",
    "        # self.features[n] = preprocessing.normalize(self.features[n])\n",
    "        #data_train[n] = preprocessing.scale(data_train[n])\n",
    "        #data_test[n] = preprocessing.scale(data_test[n])\n",
    "        combinedData[n] = preprocessing.scale(combinedData[n])\n",
    "\n",
    "dfs = np.split(combinedData, [32561], axis=0)\n",
    "data_train =dfs[0]\n",
    "data_test= dfs[1]\n",
    "#print(dfs[0].shape)\n",
    "#print(dfs[1].shape)        \n",
    "        \n",
    "#print(trainoutput)\n",
    "trainoutputArray=np.asarray(trainoutput)\n",
    "np.transpose(trainoutputArray)\n",
    "\n",
    "#data_test.preprocess()\n",
    "\n",
    "#print(trainoutputArray.ravel())\n",
    "\n",
    "#data_final_vars=data_train.columns.values.tolist()\n",
    "#print(data_train.columns.values)\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=7600)\n",
    "\"\"\"\n",
    "rfe = RFE(model, 20)\n",
    "rfe = rfe.fit(data_train, trainoutputArray.ravel())\n",
    "print(rfe.support_)\n",
    "print(data_train.columns.values)\n",
    "print (data_train.shape)\n",
    "print(rfe.ranking_)\n",
    "data_train= rfe.transform(data_train)\n",
    "data_test= rfe.transform(data_test)\n",
    "#\n",
    "#print(data_train)\n",
    "\n",
    "print (data_train.shape)\n",
    "\n",
    "\n",
    "model = SVC(gamma='auto')\n",
    "#model = RFECV(mod, step=1, cv=20)\n",
    "#model = model.fit(data_train, trainoutputArray.ravel())\n",
    "      \n",
    "\"\"\"\n",
    "print(data_train.columns.values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(7)\n",
    "n_samples, n_features = data_train.shape\n",
    "n_samplestest, n_featurestest = data_test.shape\n",
    "data_train = np.c_[data_train, random_state.randn(n_samples, 5)]\n",
    "data_test = np.c_[data_test, random_state.randn(n_samplestest, 5)]\n",
    "\n",
    "x_train, x_holdout, y_train, y_holdout = train_test_split(\n",
    "             data_train, trainoutputArray.ravel(), test_size=0.10, random_state=120)\n",
    "\n",
    "#SMOTE Oversampling\n",
    "#https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "#https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5\n",
    "sm = SMOTE(random_state = 34)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train.ravel()) #Resampled data\n",
    "\n",
    "  \n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "#https://towardsdatascience.com/cross-validation-a-beginners-guide-5b8ca04962cd\n",
    "\n",
    "\n",
    "trainindexcounter=0\n",
    "tempscore=0\n",
    "score=0\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds \n",
    "#kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    x_trainfold, x_testfold = x_train_res[train_index], x_train_res[test_index]\n",
    "    y_trainfold, y_testfold = y_train_res[train_index], y_train_res[test_index]\n",
    "    model.fit(x_trainfold, y_trainfold)\n",
    "    score = model.score(x_holdout, y_holdout)\n",
    "    trainscore = model.score(x_trainfold, y_trainfold)\n",
    "    print(\"Epoch #:\", trainindexcounter, \" Score: \",score, \"  Train Score: \",trainscore) \n",
    "    trainindexcounter+=1\n",
    "    \n",
    "    if score<bestscore:\n",
    "        break\n",
    "    tempscore=score\n",
    "    \n",
    "score=bestscore    \n",
    "#print(confusion_matrix(y_holdout, modeloutput.predict(x_holdout)))\n",
    "finalpredictions=model.predict(x_holdout)\n",
    "#predictions= model.predict(data_test)\n",
    "#print(predictions)\n",
    "\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_holdout, finalpredictions).ravel()\n",
    "\n",
    "print (\"   \")\n",
    "print(\"FINAL SCORE: \",score)\n",
    "print(\"tn=\",tn,\" fp=\" ,fp,\" fn=\", fn,\" tp=\", tp)\n",
    "print (\"   \")\n",
    "print(\"R2 score:\",  r2_score(y_holdout,finalpredictions))\n",
    "print(\"Mean squared error:\", mean_squared_error(\n",
    "              y_holdout,finalpredictions))\n",
    "\n",
    "#variance calc\n",
    "#https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/\n",
    "er = []\n",
    "g = 0\n",
    "for i in range(len(y_holdout)):\n",
    "    #print( \"actual=\", y_holdout[i], \" observed=\", finalpredictions[i])\n",
    "    x = (y_holdout[i] - finalpredictions[i]) **2\n",
    "    er.append(x)\n",
    "    g = g + x\n",
    "v = np.var(er)\n",
    "\n",
    "print (\"Variance\", v)\n",
    "print (\"   \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "ns_probs = [0 for _ in range(len(y_holdout))]\n",
    "ns_auc = roc_auc_score(y_holdout, ns_probs)\n",
    "\n",
    "lr_probs=model.predict_proba(x_holdout)\n",
    "lr_probs = lr_probs[:, 1]\n",
    "fpr, tpr,_=roc_curve(y_holdout,lr_probs) \n",
    "lr_auc= roc_auc_score( y_holdout,finalpredictions)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red', lw=2,label='ROC curve') #lw=2,\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR- False Positive')\n",
    "plt.ylabel('TPR-True Positive')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"AUC No Skill=\",ns_auc)\n",
    "print(\"AUC Logisitic=\",lr_auc)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "\n",
    "#\"\"\"\n",
    "predictions= model.predict(data_test)\n",
    "print(predictions)\n",
    "    \n",
    "        # dictionary of lists  \n",
    "dict = {'Category': predictions }  \n",
    "   \n",
    "df = pd.DataFrame(dict) \n",
    "  \n",
    "        # saving the dataframe \n",
    "df.to_csv('ScottSubmission3.csv') \n",
    "#\"\"\"\n",
    "\n",
    "#how well it can predict its own data vs holdouts \n",
    "\n",
    "#svm + nerual nets may be good for this assignm,ent\n",
    "\n",
    "#naive bayes-  potentially not great..\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "#https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "#https://towardsdatascience.com/logistic-regression-model-tuning-with-scikit-learn-part-1-425142e01af5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
